---
layout: default
title: about
permalink: /about/
nav: true
nav_order: 2
profile:
  align: right
  image: #color_logo.png
  image_circular: false # crops the image to make it circular
  more_info: 

selected_papers: false # includes a list of papers marked as "selected={true}"
social: false # includes social icons at the bottom of the page

announcements:
  enabled: false # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: false
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

## About the Lab
<div style="font-size: 1.3rem;">
<p>The Collective Intelligence Lab investigates how intelligent systems can reason, communicate, and adapt in complex, human-centered environments. We approach intelligence not as mere optimization—but as a process of representation, alignment, and coherence across multiple levels of abstraction.</p>

<p>Our lab is grounded in the belief that intelligence is inherently <strong>collective</strong>, emerging not only from individual cognition but from interaction, structure, and interpretability. We draw from computer science, cognitive science, and formal logic to build systems that reason <strong>with</strong> people—not merely in parallel to them.</p>

<p>Our work spans both theoretical foundations and applied methods, from formal models of symbolic thought and representational dynamics to novel architectures for interpretable and socially aware AI.</p>
</div>

<div class="my-5"></div>

## Why Us
<div style="font-size: 1.3rem;"> <ul> <li><strong>Socially intelligent systems</strong>: We model beliefs, norms, and values to enable AI agents that reason communicatively and ethically—essential for collaboration, trust, and human-AI alignment in real-world contexts.</li> <li><strong>Neuro-symbolic interpretability</strong>: By integrating vector symbolic architectures with language models, we develop systems that are performant yet transparent—advancing safe, controllable, and policy-aligned AI.</li> <li><strong>Coherence-driven cognition</strong>: We formalize intelligence as the restructuring of internal representations toward coherence, providing a foundation for abstraction, insight, and continual learning in adaptive agents.</li> </ul> </div>

<div class="my-5"></div>

## Director

<div class="row">
  <div class="col-md-4">
    <img src="{{ '/assets/img/prof_pic.jpg' | relative_url }}" alt="Vasanth Sarathy" class="img-fluid rounded">
  </div>
  <div class="col-md-8" style="font-size: 1.3rem;">
    <h4><strong>Vasanth Sarathy, Ph.D., J.D.</strong></h4>
    <p>Research Assistant Professor, Tufts University<br>
    Director, Collective Intelligence Lab</p>

    Vasanth's work explores the intersection of symbolic reasoning, cognitive architectures, and socially intelligent AI systems. His research has been published in top AI venues and supported by DARPA, IARPA, and the NSF. He also brings a background in law and philosophy, shaping the lab's broader interest in alignment, norms, and human-centered design.
  </div>
</div>