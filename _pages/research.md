---
layout: default
title: research
permalink: /research/
nav: true
nav_order: 3
---

## Research Overview

Our research addresses one central question:  
**How can we build intelligent systems that are structurally coherent, socially aware, and interpretable by design?**

We pursue this question across three interlinked research pillars:
<div class="row">
  <div class="col-md-4 mb-4">
    <div class="card h-100" style="background-color: rgba(253, 208, 0, 0.1);">
      <div class="card-body">
        <h3 class="card-title">1. Social Intelligence in AI</h3>
        <p>We study how artificial agents can model, infer, and respond to the beliefs, values, and intentions of others. This work includes:</p>
        <ul>
          <li>Computational models of <strong>argumentation</strong>, persuasion, and value-sensitive reasoning</li>
          <li><strong>Theory of mind</strong> in multi-agent systems and human-AI interaction</li>
          <li>Representations of <strong>trust, normativity, and alignment</strong> in conversational settings</li>
        </ul>
        <p>We build systems that debate, explain, and adapt their reasoning in collaborative and adversarial contexts—combining symbolic structure with probabilistic reasoning.</p>
      </div>
    </div>
  </div>
  
  <div class="col-md-4 mb-4">
    <div class="card h-100" style="background-color: rgba(79, 217, 189, 0.1);">
      <div class="card-body">
        <h3 class="card-title">2. Neuro-Symbolic Interpretability</h3>
        <p>Modern language models are powerful but opaque. We develop hybrid architectures that bring <strong>structure, control, and memory</strong> into these systems using tools like:</p>
        <ul>
          <li><strong>Vector Symbolic Architectures (VSAs)</strong> for encoding, manipulating, and decoding structured knowledge</li>
          <li>Symbolic <strong>guardrails and policies</strong> imposed through embedding interventions</li>
          <li>Models that retain <strong>representational consistency</strong> across prompts and contexts</li>
        </ul>
        <p>This work explores how symbolic abstractions can be mapped to and from continuous neural spaces—allowing us to intervene, constrain, and interpret LLM behavior.</p>
      </div>
    </div>
  </div>
  
  <div class="col-md-4 mb-4">
    <div class="card h-100" style="background-color: rgba(114, 131, 217, 0.1);">
      <div class="card-body">
        <h3 class="card-title">3. Coherence-Driven Cognitive Systems</h3>
        <p>We are developing a novel theory of artificial cognition grounded in <strong>representational coherence</strong>—modeling how intelligent systems restructure their internal states to reduce informational entropy and achieve conceptual insight.</p>
        <p>Key themes include:</p>
        <ul>
          <li>Dynamic <strong>concept formation and abstraction</strong></li>
          <li>Representational <strong>bifurcations</strong> and insight-driven reorganization</li>
          <li>A computational field theory of <strong>symbolic energy landscapes</strong>, implemented in gridworld simulations</li>
        </ul>
        <p>This is our most visionary line of research, aiming to build AI systems that generate and revise their own internal explanatory structures—mirroring the dynamics of human thought.</p>
      </div>
    </div>
  </div>
</div>

---

### Selected Publications

For a full list of our lab's publications please visit the [Publications](/publications/) page.

<div class="publications">
  {% bibliography --group_by none --query @*[selected=true]* %}
</div>

## Collaborations and Student Research

We work closely with undergraduate and graduate researchers across projects that span theory, engineering, and design. Our students are integral to the lab’s progress and vision, often leading experimental implementations or theoretical contributions.

To learn more or join the lab, visit our [Prospective Students](/join/) page.
