<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> research | Collective Intelligence Lab </title> <meta name="author" content=" "> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css2?family=Josefin+Sans:ital,wght@0,100..700;1,100..700&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/color_logo.png?680903ffe34d801f26db4a531fe20f6e"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://collective-intelligence-lab.github.io/research/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link rel="stylesheet" href="/assets/css/custom.css"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Collective Intelligence Lab </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">home </a> </li> <li class="nav-item "> <a class="nav-link" href="/about/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/research/">research <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/join/">prospective </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <h2 id="research-overview">Research Overview</h2> <p>Our research addresses one central question:<br> <strong>How can we build intelligent systems that are structurally coherent, socially aware, and interpretable by design?</strong></p> <p>We pursue this question across three interlinked research pillars:</p> <div class="row"> <div class="col-md-4 mb-4"> <div class="card h-100" style="background-color: rgba(253, 208, 0, 0.1);"> <div class="card-body"> <h3 class="card-title">1. Social Intelligence in AI</h3> <p>We study how artificial agents can model, infer, and respond to the beliefs, values, and intentions of others. This work includes:</p> <ul> <li>Computational models of <strong>argumentation</strong>, persuasion, and value-sensitive reasoning</li> <li> <strong>Theory of mind</strong> in multi-agent systems and human-AI interaction</li> <li>Representations of <strong>trust, normativity, and alignment</strong> in conversational settings</li> </ul> <p>We build systems that debate, explain, and adapt their reasoning in collaborative and adversarial contexts—combining symbolic structure with probabilistic reasoning.</p> </div> </div> </div> <div class="col-md-4 mb-4"> <div class="card h-100" style="background-color: rgba(79, 217, 189, 0.1);"> <div class="card-body"> <h3 class="card-title">2. Neuro-Symbolic Interpretability</h3> <p>Modern language models are powerful but opaque. We develop hybrid architectures that bring <strong>structure, control, and memory</strong> into these systems using tools like:</p> <ul> <li> <strong>Vector Symbolic Architectures (VSAs)</strong> for encoding, manipulating, and decoding structured knowledge</li> <li>Symbolic <strong>guardrails and policies</strong> imposed through embedding interventions</li> <li>Models that retain <strong>representational consistency</strong> across prompts and contexts</li> </ul> <p>This work explores how symbolic abstractions can be mapped to and from continuous neural spaces—allowing us to intervene, constrain, and interpret LLM behavior.</p> </div> </div> </div> <div class="col-md-4 mb-4"> <div class="card h-100" style="background-color: rgba(114, 131, 217, 0.1);"> <div class="card-body"> <h3 class="card-title">3. Coherence-Driven Cognitive Systems</h3> <p>We are developing a novel theory of artificial cognition grounded in <strong>representational coherence</strong>—modeling how intelligent systems restructure their internal states to reduce informational entropy and achieve conceptual insight.</p> <p>Key themes include:</p> <ul> <li>Dynamic <strong>concept formation and abstraction</strong> </li> <li>Representational <strong>bifurcations</strong> and insight-driven reorganization</li> <li>A computational field theory of <strong>symbolic energy landscapes</strong>, implemented in gridworld simulations</li> </ul> <p>This is our most visionary line of research, aiming to build AI systems that generate and revise their own internal explanatory structures—mirroring the dynamics of human thought.</p> </div> </div> </div> </div> <hr> <h3 id="selected-publications">Selected Publications</h3> <p>For a full list of our lab’s publications please visit the <a href="/publications/">Publications</a> page.</p> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">EMNLP</abbr> </div> <div id="kaveh2024emnlp" class="col-sm-8"> <div class="title">“Let’s Argue Both Sides”: Argument Generation Can Force Small Models to Utilize Previously Inaccessible Reasoning Capabilities</div> <div class="author"> Kaveh Eskandari Miandoab and Vasanth Sarathy </div> <div class="periodical"> <em>In EMNLP Workshop on Customizable NLP</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2410.12997" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Large Language Models (LLMs), despite achieving state-of-the-art results in a number of evaluation tasks, struggle to maintain their performance when logical reasoning is strictly required to correctly infer a prediction. In this work, we propose Argument Generation as a method of forcing models to utilize their reasoning capabilities when other approaches such as chain-of-thought reasoning prove insufficient. Our method involves the generation of arguments for each possible inference result, and asking the end model to rank the generated arguments. We show that Argument Generation can serve as an appropriate substitute for zero-shot prompting techniques without the requirement to add layers of complexity. Furthermore, we argue that knowledge-probing techniques such as chain-of-thought reasoning and Argument Generation are only useful when further reasoning is required to infer a prediction, making them auxiliary to more common zero-shot approaches. Finally, we demonstrate that our approach forces larger gains in smaller language models, showcasing a complex relationship between model size and prompting methods. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">kaveh2024emnlp</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{“Let’s Argue Both Sides”: Argument Generation Can Force Small Models to Utilize Previously Inaccessible Reasoning Capabilities}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Miandoab, Kaveh Eskandari and Sarathy, Vasanth}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{EMNLP Workshop on Customizable NLP}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">theme</span> <span class="p">=</span> <span class="s">{social}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">EMNLP</abbr> </div> <div id="umair2024emnlp" class="col-sm-8"> <div class="title">Large Language Models Know What To Say But Not When To Speak</div> <div class="author"> Muhammad Umair, Vasanth Sarathy, and Jan Ruiter </div> <div class="periodical"> <em>In Findings of the Association for Computational Linguistics: EMNLP</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2410.16044" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://osf.io/k5pc9/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Supp</a> <a href="/assets/pdf/umair2024emnlp_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>Turn-taking is a fundamental aspect of human communication, essential for smooth and comprehensible verbal interactions. While recent advances in Large Language Models (LLMs) have shown promise in enhancing Spoken Dialogue Systems (SDS), existing models often falter in natural, unscripted conversations due to their being trained on mostly written language, and focus only on turn-final Transition Relevance Places (TRPs). This paper addresses these limitations by evaluating the ability of state-of-the-art LLMs to predict within-turn TRPs, which are crucial for natural dialogue but challenging to predict. We introduce a new and unique dataset of participant-labeled within-turn TRPs and evaluate the accuracy of TRP prediction by state-of-the art LLMs. Our experiments demonstrate the limitations of LLMs in modeling spoken language dynamics and pave the way for developing more responsive and naturalistic spoken dialogue systems.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">umair2024emnlp</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Large Language Models Know What To Say But Not When To Speak}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Umair, Muhammad and Sarathy, Vasanth and Ruiter, Jan}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Findings of the Association for Computational Linguistics: EMNLP}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">theme</span> <span class="p">=</span> <span class="s">{social}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">IJCAI</abbr> </div> <div id="goldowsky2024ijcai" class="col-sm-8"> <div class="title">Analogical Reasoning Within a Conceptual Hyperspace</div> <div class="author"> Howard Goldowsky and Vasanth Sarathy </div> <div class="periodical"> <em>In IJCAI Workshop on Analogical Abstraction in Cognition, Perception, and Language</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/goldowsky2024ijcai.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>We propose an approach to analogical inference that marries the neuro-symbolic computational power of complex-sampled hyperdimensional computing (HDC) with Conceptual Spaces Theory (CST), a promising theory of semantic meaning. CST sketches, at an abstract level, approaches to analogical inference that go beyond the standard predicate-based structure mapping theories. But it does not describe how such an approach can be operationalized. We propose a concrete HDC-based architecture that computes several types of analogy classified by CST. We present preliminary proof-of-concept experimental results within a toy domain and describe how it can perform category-based and property-based analogical reasoning.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">goldowsky2024ijcai</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Analogical Reasoning Within a Conceptual Hyperspace}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Goldowsky, Howard and Sarathy, Vasanth}</span><span class="p">,</span>
  <span class="na">maintitle</span> <span class="p">=</span> <span class="s">{IJCAI 2024: 33rd International Joint Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IJCAI Workshop on Analogical Abstraction in Cognition, Perception, and Language}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">theme</span> <span class="p">=</span> <span class="s">{neurosymbolic}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">CogSci</abbr> </div> <div id="sarathy2024cogsci" class="col-sm-8"> <div class="title">Using Puzzle Video Games to Study Cognitive Processes in Human Insight and Creative Problem-Solving</div> <div class="author"> Vasanth Sarathy, Nicholas Rabb, Daniel Kasenberg, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Matthias Scheutz' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of the 46th Annual Meeting of the Cognitive Science Society</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://escholarship.org/uc/item/4bc4q23t" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/sarathy2024cogsci.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Classical approaches to studying insight problem-solving typically use specialized problems (e.g., nine-dot problem, compound-remote associates task) as stimuli together with verbal reports from subjects during problem-solving to reveal their thought processes, possibly adding other task-related metrics such as completion rate and physiological measures like eye fixation and neural activity. This approach has led to the claims that insight and creative thought require impasse and mental restructuring. What is missing from this literature is a cognitive process model of insight, and one reason for the lack of such a model is the lack of a unified, scalable, and tunable experimental framework with which to study human creative problem-solving with higher fidelity. In this paper, we introduce ESCAPE, an experimental paradigm using puzzle video games as stimuli which allow for the collection of process data that can serve as a basis for computational models. We have specifically developed a set of puzzle games based on this paradigm and conducted experiments that demonstrate the utility of the approach by revealing a set of computational principles that need to be accounted for by a theory of creative problems and the computational models based on it.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">sarathy2024cogsci</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Using Puzzle Video Games to Study Cognitive Processes in Human Insight and Creative Problem-Solving}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sarathy, Vasanth and Rabb, Nicholas and Kasenberg, Daniel and Scheutz, Matthias}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 46th Annual Meeting of the Cognitive Science Society}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">theme</span> <span class="p">=</span> <span class="s">{coherence}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">AAMAS</abbr> </div> <div id="shukla2023lgts" class="col-sm-8"> <div class="title">LgTS: Dynamic Task Sampling using LLM-generated sub-goals for Reinforcement Learning Agents</div> <div class="author"> Yash Shukla, Wenchang Gao, Vasanth Sarathy, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Alvaro Velasquez, Robert Wright, Jivko Sinapov' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems (AAMAS)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2310.09454" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dl.acm.org/doi/10.5555/3635637.3663035" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/shukla2023lgts.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Recent advancements in reasoning abilities of Large Language Models (LLM) has promoted their usage in problems that require high-level planning for robots and artificial agents. However, current techniques that utilize LLMs for such planning tasks make certain key assumptions such as, access to datasets that permit finetuning, meticulously engineered prompts that only provide relevant and essential information to the LLM, and most importantly, a deterministic approach to allow execution of the LLM responses either in the form of existing policies or plan operators. In this work, we propose LgTS (LLM-guided Teacher-Student learning), a novel approach that explores the planning abilities of LLMs to provide a graphical representation of the sub-goals to a reinforcement learning (RL) agent that does not have access to the transition dynamics of the environment. The RL agent uses Teacher-Student learning algorithm to learn a set of successful policies for reaching the goal state from the start state while simultaneously minimizing the number of environmental interactions. Unlike previous methods that utilize LLMs, our approach does not assume access to a propreitary or a fine-tuned LLM, nor does it require pre-trained policies that achieve the sub-goals proposed by the LLM. Through experiments on a gridworld based DoorKey domain and a search-and-rescue inspired domain, we show that generating a graphical structure of sub-goals helps in learning policies for the LLM proposed sub-goals and the Teacher-Student learning algorithm minimizes the number of environment interactions when the transition dynamics are unknown.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">shukla2023lgts</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{LgTS: Dynamic Task Sampling using LLM-generated sub-goals for Reinforcement Learning Agents}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shukla, Yash and Gao, Wenchang and Sarathy, Vasanth and Velasquez, Alvaro and Wright, Robert and Sinapov, Jivko}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems (AAMAS)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">theme</span> <span class="p">=</span> <span class="s">{neurosymbolic}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">LREC-COLING</abbr> </div> <div id="benkler_2024_value_resonance" class="col-sm-8"> <div class="title">Recognizing Value Resonance with Resonance-Tuned RoBERTa Task Definition, Experimental Validation, and Robust Modeling</div> <div class="author"> Noam Benkler, Scott Friedman, Sonja Schmer-Galunder, and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Drisana Mosaphir, Robert Goldman, Ruta Wheelock, Vasanth Sarathy, Pavan Kantharaju, Matthew McLure' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING)</em>, Dec 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/benkler_2024_value_resonance.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Understanding the implicit values and beliefs of diverse groups and cultures using qualitative texts – such as long-form narratives – and domain-expert interviews is a fundamental goal of social anthropology. This paper builds upon a 2022 study that introduced the NLP task of Recognizing Value Resonance (RVR) for gauging perspective – positive, negative, or neutral – on implicit values and beliefs in textual pairs. This study included a novel hand-annotated dataset, the World Values Corpus (WVC), designed to simulate the task of RVR, and a transformer-based model, Resonance-Tuned RoBERTa, designed to model the task. We extend existing work by refining the task definition and releasing the World Values Corpus (WVC) dataset. We further conduct several validation experiments designed to robustly evaluate the need for task specific modeling, even in the world of LLMs. Finally, we present two additional Resonance-Tuned models trained over extended RVR datasets, designed to improve RVR model versatility and robustness. Our results demonstrate that the Resonance-Tuned models outperform top-performing Recognizing Textual Entailment (RTE) models in recognizing value resonance as well as zero-shot GPT-3.5 under several different prompt structures, emphasizing its practical applicability. Our findings highlight the potential of RVR in capturing cultural values within texts and the importance of task-specific modeling.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">benkler_2024_value_resonance</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Recognizing Value Resonance with Resonance-Tuned RoBERTa Task Definition, Experimental Validation, and Robust Modeling}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Benkler, Noam and Friedman, Scott and Schmer-Galunder, Sonja and Mosaphir, Drisana and Goldman, Robert and Wheelock, Ruta and Sarathy, Vasanth and Kantharaju, Pavan and McLure, Matthew}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING)}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{International Committee on Computational Linguistics}</span><span class="p">,</span>
  <span class="na">theme</span> <span class="p">=</span> <span class="s">{social}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ACS</abbr> </div> <div id="sarathyargumentation2022" class="col-sm-8"> <div class="title">A Neuro-Symbolic Cognitive System for Intuitive Argumentation</div> <div class="author"> Vasanth Sarathy, Mark Burstein, Scott Friedman, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Robert Bobrow, Ugur Kuter' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the Tenth Annual Conference on Advances in Cognitive Systems</em>, Dec 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/sarathyargumentation2022" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Making and evaluating arguments is an important cognitive capability that plays a vital role in human cooperation by allowing us to communicate beliefs and persuade others. In this paper, we ask how can machines comprehend arguments. Research in computational argumentation has a rich history of addressing questions about the abstract dynamics of argumentation and how argument structures can be mined from text. However, what is missing is an integrated cognitive system that provides a computational account for how we might intuitively make sense of arguments. Work in cognitive psychology has suggested that when presented with a novel argument, humans interpret the language and produce acceptability/coherence judgments intuitively. In this paper, we introduce SKEPTIC, a computational implementation of the process of intuitive argumentation, combining modern deep neural networks and natural language processing techniques with established cognitive systems principles. We describe an architecture and an algorithm for extracting graphlike argument structures from raw unstructured text as well as retrieving implicit assumptions that support the argument. Being able to extract arguments and their implicit assumptions will be able to help us detect misinformation, reduce polarization, understand social and cultural rationales, and assist with critical thinking and persuasive writing.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">sarathyargumentation2022</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Neuro-Symbolic Cognitive System for
                   Intuitive Argumentation}</span><span class="p">,</span>
  <span class="na">language</span> <span class="p">=</span> <span class="s">{en}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the {Tenth} {Annual} {Conference} on {Advances} in {Cognitive} {Systems}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sarathy, Vasanth and Burstein, Mark and Friedman, Scott and Bobrow, Robert and Kuter, Ugur}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">theme</span> <span class="p">=</span> <span class="s">{social}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICDL</abbr> </div> <div id="goel2022rapid" class="col-sm-8"> <div class="title">RAPid-Learn: A Framework for Learning to Recover for Handling Novelties in Open-World Environments</div> <div class="author"> Shivam Goel, Yash Shukla, Vasanth Sarathy, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Matthias Scheutz, Jivko Sinapov' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In 2022 IEEE International Conference on Development and Learning</em>, Dec 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2206.12493" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/goel2022rapid.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>We propose RAPid-Learn: Learning to Recover and Plan Again, a hybrid planning and learning method, to tackle the problem of adapting to sudden and unexpected changes in an agent’s environment (i.e., novelties). RAPid-Learn is designed to formulate and solve modifications to a task’s Markov Decision Process (MDPs) on-the-fly and is capable of exploiting domain knowledge to learn any new dynamics caused by the environmental changes. It is capable of exploiting the domain knowledge to learn action executors which can be further used to resolve execution impasses, leading to a successful plan execution. This novelty information is reflected in its updated domain model. We demonstrate its efficacy by introducing a wide variety of novelties in a gridworld environment inspired by Minecraft, and compare our algorithm with transfer learning baselines from the literature. Our method is (1) effective even in the presence of multiple novelties, (2) more sample efficient than transfer learning RL baselines, and (3) robust to incomplete model information, as opposed to pure symbolic planning approaches.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">goel2022rapid</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{RAPid-Learn: A Framework for Learning to
                    Recover for Handling Novelties in Open-World Environments}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Goel, Shivam and Shukla, Yash and Sarathy, Vasanth and Scheutz, Matthias and Sinapov, Jivko}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2022 IEEE International Conference on Development and Learning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">theme</span> <span class="p">=</span> <span class="s">{neurosymbolic}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ACS</abbr> </div> <div id="friedmanunstructured2021" class="col-sm-8"> <div class="title">From Unstructured Text to Causal Knowledge Graphs: A Transformer-Based Approach</div> <div class="author"> Scott Friedman, Ian Magnusson, Vasanth Sarathy, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Sonja Schmer-Galunder' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of the Ninth Annual Conference on Advances in Cognitive Systems</em>, Dec 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2202.11768" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/friedmanunstructured2021.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Qualitative causal relationships compactly express the direction, dependency, temporal constraints, and monotonicity constraints of discrete or continuous interactions in the world. In everyday or academic language, we may express interactions between quantities (e.g., sleep decreases stress), between discrete events or entities (e.g., a protein inhibits another protein’s transcription), or between intentional or functional factors (e.g., hospital patients pray to relieve their pain). Extracting and representing these diverse causal relations are critical for cognitive systems that operate in domains spanning from scientific discovery to social science. This paper presents a transformer-based NLP architecture that jointly extracts knowledge graphs including (1) variables or factors described in language, (2) qualitative causal relationships over these variables, (3) qualifiers and magnitudes that constrain these causal relationships, and (4) word senses to localize each extracted node within a large ontology. We do not claim that our transformer-based architecture is itself a cognitive system; however, we provide evidence of its accurate knowledge graph extraction in real-world domains and the practicality of its resulting knowledge graphs for cognitive systems that perform graph-based reasoning. We demonstrate this approach and include promising results in two use cases, processing textual inputs from academic publications, news articles, and social media.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">friedmanunstructured2021</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{From {Unstructured} {Text} to {Causal} {Knowledge} {Graphs}: {A} {Transformer}-{Based} {Approach}}</span><span class="p">,</span>
  <span class="na">language</span> <span class="p">=</span> <span class="s">{en}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the {Ninth} {Annual} {Conference} on {Advances} in {Cognitive} {Systems}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Friedman, Scott and Magnusson, Ian and Sarathy, Vasanth and Schmer-Galunder, Sonja}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{18}</span><span class="p">,</span>
  <span class="na">theme</span> <span class="p">=</span> <span class="s">{neurosymbolic}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">AAMAS</abbr> </div> <div id="sarathy2021aamas" class="col-sm-8"> <div class="title">SPOTTER: Extending Symbolic Planning Operators through Targeted Reinforcement Learning</div> <div class="author"> Vasanth Sarathy, Daniel Kasenberg, Shivam Goel, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Jivko Sinapov, Matthias Scheutz' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 20th International Conference on Autonomous Agents and Multiagent Systems</em>, Dec 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2012.13037" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/sarathy2021aamas.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Symbolic planning models allow decision-making agents to sequence actions in arbitrary ways to achieve a variety of goals in dynamic domains. However, they are typically handcrafted and tend to require precise formulations that are not robust to human error. Reinforcement learning (RL) approaches do not require such models, and instead learn domain dynamics by exploring the environment and collecting rewards. However, RL approaches tend to require millions of episodes of experience and often learn policies that are not easily transferable to other tasks. In this paper, we address one aspect of the open problem of integrating these approaches: how can decision-making agents resolve discrepancies in their symbolic planning models while attempting to accomplish goals? We propose an integrated framework named SPOTTER that uses RL to augment and support ("spot") a planning agent by discovering new operators needed by the agent to accomplish goals that are initially unreachable for the agent. SPOTTER outperforms pure-RL approaches while also discovering transferable symbolic knowledge and does not require supervision, successful plan traces or any a priori knowledge about the missing planning operator.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">sarathy2021aamas</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{SPOTTER: Extending Symbolic Planning Operators through Targeted Reinforcement Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sarathy, Vasanth and Kasenberg, Daniel and Goel, Shivam and Sinapov, Jivko and Scheutz, Matthias}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 20th International Conference on Autonomous Agents and Multiagent Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
  <span class="na">theme</span> <span class="p">=</span> <span class="s">{neurosymbolic}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">COLING</abbr> </div> <div id="sarathy2020reasoning" class="col-sm-8"> <div class="title">Reasoning Requirements for Indirect Speech Act Interpretation</div> <div class="author"> Vasanth Sarathy, Alexander Tsuetaki, Antonio Roque, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Matthias Scheutz' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of the 28th International Conference on Computational Linguistics</em>, Dec 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://aclanthology.org/2020.coling-main.433/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/sarathy2020reasoning" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>We perform a corpus analysis to develop a representation of the knowledge and reasoning used to interpret indirect speech acts. An indirect speech act (ISA) is an utterance whose intended meaning is different from its literal meaning. We focus on those speech acts in which slight changes in situational or contextual information can switch the dominant intended meaning of an utterance from direct to indirect or vice-versa. We computationalize how various contextual features can influence a speaker’s beliefs, and how these beliefs can influence the intended meaning and choice of the surface form of an utterance. We axiomatize the domain-general patterns of reasoning involved, and implement a proof-of-concept architecture using Answer Set Programming. Our model is presented as a contribution to cognitive science and psycholinguistics, so representational decisions are justified by existing theoretical work.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">sarathy2020reasoning</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Reasoning Requirements for Indirect Speech Act Interpretation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sarathy, Vasanth and Tsuetaki, Alexander and Roque, Antonio and Scheutz, Matthias}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 28th International Conference on Computational Linguistics}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">theme</span> <span class="p">=</span> <span class="s">{social}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">THRI</abbr> </div> <div id="sarathythri2019" class="col-sm-8"> <div class="title">When Exceptions Are the Norm: Exploring the Role of Consent in HRI</div> <div class="author"> Vasanth Sarathy, Thomas Arnold, and Matthias Scheutz </div> <div class="periodical"> <em>ACM Transactions on Human-Robot Interaction (Formerly, Journal of Human-Robot Interaction)</em>, Jul 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dl.acm.org/doi/abs/10.1145/3341166" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/sarathythri2019.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>HRI researchers have made major strides in developing robotic architectures that are capable of reading a limited set of social cues and producing behaviors that enhance their likeability and feeling of comfort amongst humans. However, the cues in these models are fairly direct and the interactions largely dyadic. To capture the normative qualities of interaction more robustly, we propose “consent” as a distinct, critical area for HRI research. Convening important insights in existing HRI work around topics like touch, proxemics, gaze, and moral norms, the notion of consent reveals key expectations that can shape how a robot acts in social spaces. Consent need not be limited to just an explicit permission given in ethically charged or normatively risky scenarios. Instead, it is a richer notion, one that covers even implicit acquiescence in scenarios that otherwise seem normatively neutral. By sorting various kinds of consent through social and legal doctrine, we delineate empirical and technical questions to meet consent challenges faced in major application domains and robotic roles. Attention to consent could show, for example, how extraordinary, norm-violating actions can be justified by agents and accepted by those around them. We argue that operationalizing ideas from legal scholarship can better guide how robotic systems might cultivate and sustain proper forms of consent.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">sarathythri2019</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sarathy, Vasanth and Arnold, Thomas and Scheutz, Matthias}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{When Exceptions Are the Norm: Exploring
                   the Role of Consent in HRI}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ACM Transactions on Human-Robot Interaction (Formerly, Journal of
                   Human-Robot Interaction)}</span><span class="p">,</span>
  <span class="na">issue_date</span> <span class="p">=</span> <span class="s">{August 2019}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{3}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{14:1--14:21}</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{14}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{21}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ACM}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">theme</span> <span class="p">=</span> <span class="s">{social}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Frontiers (Neuro)</abbr> </div> <div id="sarathy2018real" class="col-sm-8"> <div class="title">Real World Problem-Solving</div> <div class="author"> Vasanth Sarathy </div> <div class="periodical"> <em>Frontiers in Human Neuroscience</em>, Jul 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.frontiersin.org/articles/10.3389/fnhum.2018.00261/full" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/sarathy2018real.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Real world problem-solving (RWPS) is what we do every day. It requires flexibility, resilience, resourcefulness, and a certain degree of creativity. A crucial feature of RWPS is that it involves continuous interaction with the environment during the problem-solving process. In this process, the environment can be seen as not only a source of inspiration for new ideas but also as a tool to facilitate creative thinking. The cognitive neuroscience literature in creativity and problem-solving is extensive, but it has largely focused on neural networks that are active when subjects are not focused on the outside world, i.e., not using their environment. In this paper, I attempt to combine the relevant literature on creativity and problem-solving with the scattered and nascent work in perceptually-driven learning from the environment. I present my synthesis as a potential new theory for real world problem-solving and map out its hypothesized neural basis. I outline some testable predictions made by the model and provide some considerations and ideas for experimental paradigms that could be used to evaluate the model more thoroughly.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">sarathy2018real</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Real World Problem-Solving}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sarathy, Vasanth}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Frontiers in Human Neuroscience}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Frontiers Media SA}</span><span class="p">,</span>
  <span class="na">theme</span> <span class="p">=</span> <span class="s">{coherence}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">CogSci</abbr> </div> <div id="sarathyetal2017cogsci" class="col-sm-8"> <div class="title">Mental Representations and Computational Modeling of Context-Specific Human Norm Systems</div> <div class="author"> Vasanth Sarathy, Matthias Scheutz, Joseph Austerweil, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Yoed Kenett, Mowafak Allaham, Bertram Malle' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 39th Annual Meeting of the Cognitive Science Society</em>, Jul 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/sarathyetal2017cogsci.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Human behavior is frequently guided by social and moral norms; in fact, no societies, no social groups could exist without norms. However, there are few cognitive science approaches to this central phenomenon of norms. While there has been some progress in developing formal representations of norm systems (eg, deontological approaches), we do not yet know basic properties of human norms: how they are represented, activated, and learned. Further, what computational models can capture these properties, and what algorithms could learn them? In this paper we describe initial experiments on human norm representations in which the context specificity of norms features prominently. We then provide a formal representation of norms using Dempster-Shafer Theory that allows a machine learning algorithm to learn norms under uncertainty from these human data, while preserving their context specificity.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">sarathyetal2017cogsci</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Mental Representations and Computational
                   Modeling of Context-Specific Human Norm Systems}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sarathy, Vasanth and Scheutz, Matthias and Austerweil, Joseph and Kenett, Yoed and Allaham, Mowafak and Malle, Bertram}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 39th Annual Meeting of the Cognitive Science Society}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">theme</span> <span class="p">=</span> <span class="s">{social}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <h2 id="collaborations-and-student-research">Collaborations and Student Research</h2> <p>We work closely with undergraduate and graduate researchers across projects that span theory, engineering, and design. Our students are integral to the lab’s progress and vision, often leading experimental implementations or theoretical contributions.</p> <p>To learn more or join the lab, visit our <a href="/join/">Prospective Students</a> page.</p> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 . Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>